# 验证码识别作业报告

## 使用方法

与train.py同目录的dataset/train/images里放置原始数据集图片，dataset/train下放置标签文件，然后运行tools.py里的split_and_resize_images函数得到对图片做分割处理后的train_final数据集以及对应标签文件

然后运行train.py文件进行训练

最后使用predict_single.py生成预测文件submission.csv



## 一、模型原理

### 1.1 多任务学习框架
本项目采用**多任务学习**（Multi-Task Learning, MTL）框架，同时处理验证码识别中的两个关键任务：

1. **字符识别任务**：将验证码中的字符分类为36个类别（26个英文字母A-Z + 10个数字0-9）
2. **颜色识别任务**：判断验证码字符的颜色类别（2分类问题）

多任务学习的核心思想是通过共享底层特征表示，让模型学习到对多个相关任务都有用的通用特征。在本任务中，字符形状和颜色信息存在内在关联，共享特征提取器可以提高数据利用效率，增强模型的泛化能力。

### 1.2 残差网络原理
模型基于**ResNet-18**（残差网络）架构，采用了残差学习的基本思想：

**残差块结构**：
```
输入 → 卷积层1 → BatchNorm → ReLU → 卷积层2 → BatchNorm → 跳跃连接 → 输出
```
残差学习的核心公式：
$$
y = F(x, W_i) + x
$$
其中：
- $x$：输入特征
- $F(x, W_i)$：残差映射
- $y$：输出特征

这种结构通过引入**跳跃连接**（skip connection），解决了深度神经网络中的梯度消失和梯度爆炸问题，使得能够训练更深的网络。

## 二、模型结构

### 2.1 整体架构
本模型采用改进的ResNet-18多任务网络，具体结构如下：

```
输入图像(3×40×60)
    ↓
卷积层(3×3, 64通道, stride=1, padding=1)
    ↓
BatchNorm + ReLU
    ↓
最大池化(2×2, stride=1)
    ↓
残差层1: 2×64→64
    ↓
残差层2: 2×64→128, stride=2
    ↓
残差层3: 2×128→256, stride=2
    ↓
残差层4: 2×256→512, stride=2
    ↓
全局平均池化
    ↓
展平层(512维)
    ↓
共享全连接层(512→256)
    ↓
    ├── 字符分类头(256→36)
    │       └── 输出字符预测
    │
    └── 颜色分类头(256→2)
            └── 输出颜色预测
```

### 2.2 各层详细配置

| 层名称 | 类型 | 参数配置 | 输出尺寸 | 参数量 |
|--------|------|----------|-----------|--------|
| 输入层 | 图像输入 | 3通道, 40×60 | (batch, 3, 40, 60) | - |
| conv1 | Conv2d | 3×3, 64, s=1, p=1 | (batch, 64, 40, 60) | 1,728 |
| bn1 | BatchNorm2d | 64通道 | (batch, 64, 40, 60) | 128 |
| 最大池化 | MaxPool2d | 2×2, s=1 | (batch, 64, 20, 30) | - |
| layer1 | BasicBlock×2 | 64→64, stride=1 | (batch, 64, 20, 30) | 148,736 |
| layer2 | BasicBlock×2 | 64→128, stride=2 | (batch, 128, 10, 15) | 526,336 |
| layer3 | BasicBlock×2 | 128→256, stride=2 | (batch, 256, 5, 8) | 2,101,248 |
| layer4 | BasicBlock×2 | 256→512, stride=2 | (batch, 512, 3, 4) | 8,392,704 |
| 全局池化 | AdaptiveAvgPool2d | 1×1 | (batch, 512, 1, 1) | - |
| 共享FC1 | Linear | 512→512 | (batch, 512) | 262,656 |
| 共享FC2 | Linear | 512→256 | (batch, 256) | 131,328 |
| 字符头 | Linear | 256→36 | (batch, 36) | 9,252 |
| 颜色头 | Linear | 256→2 | (batch, 2) | 514 |

**总计参数**：约1,174万可训练参数

### 2.3 关键设计决策

1. **输入尺寸调整**：验证码图像统一调整为40×60像素，在保持纵横比的同时减少计算复杂度
2. **初始卷积层**：使用3×3小卷积核和stride=1，避免过早丢失空间信息
3. **多任务头设计**：
   - 字符分类头：36个输出节点，使用softmax交叉熵损失
   - 颜色分类头：2个输出节点，适用于二分类问题
4. **共享特征层**：中间256维特征层同时为两个任务提供高级语义特征

## 三、调参训练过程

### 3.1 超参数配置

经过多次实验，确定的最优超参数组合：

| 参数 | 值 | 说明 |
|------|-----|------|
| Batch Size | 512 | 权衡训练速度和内存消耗 |
| 初始学习率 | 0.001 | 使用较小的学习率保证稳定收敛 |
| 优化器 | AdamW | 带权重衰减的Adam优化器 |
| 权重衰减 | 0.01 | 防止过拟合 |
| 最大Epoch数 | 100 | 充分训练 |
| 验证集比例 | 20% | 用于模型选择和早停 |
| 损失权重 | 字符:1.0, 颜色:0.1 | 侧重字符识别任务 |
| 类别权重 | [0,1,14,18,24]类权重提高 | 针对易混淆字符 |

### 3.2 训练策略

#### 3.2.1 学习率调度
采用**ReduceLROnPlateau**调度器：
```python
scheduler = ReduceLROnPlateau(
    opt, 
    mode='min',
    factor=2/3,      # 学习率衰减因子
    patience=5,      # 容忍5个epoch无改善
    threshold=0.0001,
    cooldown=5,      # 调整后的冷却期
    min_lr=0.0001    # 最小学习率
)
```
当验证损失在连续5个epoch内没有相对改善超过0.01%时，学习率乘以2/3。

#### 3.2.2 损失函数设计
采用**加权多任务损失函数**：
$$
\mathcal{L}_{\text{total}} = \alpha \cdot \mathcal{L}_{\text{char}} + \beta \cdot \mathcal{L}_{\text{color}}
$$
其中：
- $alpha = 1.0$（字符损失权重）
- $beta = 0.1$（颜色损失权重）
- $mathcal{L}_{\text{char}}$：带类别权重的交叉熵损失
- $mathcal{L}_{\text{color}}$：标准交叉熵损失

针对易混淆字符（0/O, 1/I等）设置更高的类别权重，提高模型对这些字符的辨别能力。

### 3.3 数据预处理

1. **数据分割**：根据人眼的观察，将图像内的五个字符按照横轴百分比23%, 40%, 59%, 76%这四个位置切割，基本上可以实现字符分离。如此分割后统一拉伸或压缩到40*60的图像大小再作后续处理。
1. **数据加载**：从`./dataset/train_final/`加载图像和标签
2. **数据划分**：80%训练集，20%验证集
3. **数据标准化**：转换为Tensor并归一化到[0,1]范围

### 3.4 训练过程监控

训练过程中实时监控以下指标：

1. **训练损失**：每个batch的损失值
2. **验证损失**：每个epoch结束后的验证集损失
3. **准确率指标**：
   - 字符级准确率
   - 颜色级准确率
   - 样本级准确率（字符和颜色都正确）

### 3.5 模型选择与保存

采用**最佳模型保存策略**：
```python
if val_sample_acc > best_val_sample_acc:
    best_val_sample_acc = val_sample_acc
    torch.save(model.state_dict(), model_path)
```
基于验证集的样本级准确率选择最佳模型，避免过拟合。

### 3.6 训练性能优化

1. **GPU加速**：使用CUDA进行GPU加速训练
2. **批量处理**：batch_size=512平衡内存使用和训练稳定性
3. **梯度裁剪**：防止梯度爆炸

### 3.7 实验结果

经过100个epoch的训练（大多时候靠后面的轮次几乎没有进步），模型在测试集上达到以下性能：



**训练时间**：约5小时（NVIDIA RTX 4090）（训练时长有些记不清了，后面没有进步的时候一般直接手动打断）

### 3.8 调参经验总结

1. **学习率选择**：初始学习率0.001配合调度器效果最佳
2. **批量大小**：512在训练速度和泛化性能间取得平衡
3. **权重分配**：字符:颜色=1:0.1的权重比在多任务学习中表现较优
4. **正则化**：0.01的权重衰减有效控制过拟合
5. **类别平衡**：对易混淆字符提高权重，轻微改善识别率

该训练方案在验证码识别任务上达到了较高的准确率，证明了多任务残差网络的有效性。