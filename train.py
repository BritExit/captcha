import torch
import torch.nn as nn
from torch.utils.data import DataLoader, random_split
from torchvision.transforms import ToTensor, Compose
from Testmodel import CNN, ResNet18MultiTask, EfficientCharNet
from datasets import CaptchaData
import time
import sys
from torchvision.transforms import RandomRotation, RandomAffine, ColorJitter, RandomPerspective
import math
from torch.optim.lr_scheduler import ReduceLROnPlateau, CosineAnnealingLR, SequentialLR, LambdaLR

# batch_size = 1024
# batch_size = 64
# batch_size = 64
# lr = 0.0005 * math.sqrt(batch_size / 64)
# batch_size = 1024; lr = 0.001; MAX_TOTAL_SAMPLES = 200000
batch_size = 512; lr = 0.001; MAX_TOTAL_SAMPLES = 200000
# batch_size = 512, lr = 0.004
# batch_size = 256; lr = 0.001; MAX_TOTAL_SAMPLES = 100000
# batch_size = 256; lr = 0.002; MAX_TOTAL_SAMPLES = 200000
max_epoch = 100
model_path = "./checkpoints/model.pth"
char_weight, color_weight = 1, 0.1 #
# 21å·è®°å¾—è¯•ä¸€ä¸‹0.1çš„è¿™ä¸ªå‚æ•° 
# char_weight, color_weight = 0, 1 # åªå…³æ³¨é¢œè‰²
# color_weight = 0.0
use_scheduler = True
use_color_only = False
use_evaluate_fast = False

val_ratio = 0.2  # 20%çš„æ•°æ®ç”¨ä½œéªŒè¯é›†

# æ¯”è¾ƒå¤šçš„é”™è¯¯ 0 O 1 I
# F
# T
# J
# L
# 5
# E
num_classes = 36
class_weights = torch.ones(num_classes)  
class_weights[0] = 2.0
class_weights[1] = 2.0
class_weights[14] = 2.0
class_weights[18] = 2.0
class_weights[24] = 3.0
class_weights = class_weights.to('cuda')

def print_header(text):
    """æ‰“å°æ ‡é¢˜"""
    print("\n" + "=" * 60)
    print(f"  {text}")
    print("=" * 60)


def print_subheader(text):
    """æ‰“å°å­æ ‡é¢˜"""
    print(f"\n{'â”€' * 40}")
    print(f"  {text}")
    print(f"{'â”€' * 40}")


def evaluate_fast_no_color(model, data_loader, loss_fn, device, max_samples=10000):
    """å¿«é€Ÿè¯„ä¼°ç‰ˆæœ¬"""
    model.eval()
    total_loss = 0.0
    char_correct = 0
    char_total = 0
    
    with torch.no_grad():
        for img, char_gt, _ in data_loader:
            img = img.to(device)
            char_gt = char_gt.to(device)
            
            char_out, color_out = model(img)
            loss = loss_fn(char_out, char_gt)
            total_loss += loss.item() * img.size(0)
            
            char_pred = char_out.argmax(dim=1)
            char_correct += (char_pred == char_gt).sum().item()
            char_total += img.size(0)
            
            if char_total >= max_samples:
                break
    
    if char_total == 0:
        return 0.0, 0.0, 0.0, 0.0
    
    avg_loss = total_loss / char_total
    char_acc = char_correct / char_total * 100
    
    return avg_loss, char_acc, 1, char_acc

# æ·»åŠ ï¼šè¯„ä¼°å‡½æ•°
def evaluate(model, data_loader, loss_char_fn, loss_color_fn, device, max_samples=10000):
    # if use_evaluate_fast:
    #     return evaluate_fast(model, data_loader, loss_fn, device=device, max_samples=10000)

    """è¯„ä¼°æ¨¡å‹åœ¨æ•°æ®é›†ä¸Šçš„æ€§èƒ½"""
    model.eval()
    total_loss = 0.0
    char_correct = 0
    color_correct = 0
    char_total = 0
    color_total = 0
    sample_correct = 0
    total_samples = 0

    with torch.no_grad():
        for img, char_gt, color_gt in data_loader:
            img = img.to(device)
            char_gt = char_gt.to(device)
            color_gt = color_gt.to(device)

            # å‰å‘ä¼ æ’­
            char_out, color_out = model(img)

            # è®¡ç®—æŸå¤±
            loss_char = loss_char_fn(char_out, char_gt)
            loss_color = loss_color_fn(color_out, color_gt)
            loss = char_weight * loss_char + color_weight * loss_color
            total_loss += loss.item() * img.size(0)

            # è®¡ç®—å‡†ç¡®ç‡
            batch_size = img.size(0)
            char_total += batch_size * 1  # 5ä¸ªå­—ç¬¦
            color_total += batch_size * 1  # 5ä¸ªé¢œè‰²ä½ç½®
            total_samples += batch_size

            # å­—ç¬¦å‡†ç¡®ç‡
            char_pred = char_out.view(batch_size, 1, 36).argmax(dim=2)
            char_target = char_gt.view(batch_size, 1, 36).argmax(dim=2)
            char_correct += (char_pred == char_target).sum().item()

            # é¢œè‰²å‡†ç¡®ç‡
            color_pred = color_out.view(batch_size, 1, 2).argmax(dim=2)
            color_target = color_gt.view(batch_size, 1, 2).argmax(dim=2)
            color_correct += (color_pred == color_target).sum().item()

            # æ ·æœ¬å‡†ç¡®ç‡ï¼ˆæ‰€æœ‰å­—ç¬¦å’Œé¢œè‰²éƒ½æ­£ç¡®ï¼‰
            char_correct_all = (char_pred == char_target).all(dim=1)
            color_correct_all = (color_pred == color_target).all(dim=1)
            # sample_correct += (char_correct_all).sum().item()
            if use_color_only:
                sample_correct += (color_correct_all).sum().item()
            else:
                sample_correct += (char_correct_all & color_correct_all).sum().item()
            

            if char_total >= max_samples:
                break

    avg_loss = total_loss / total_samples
    char_acc = char_correct / char_total * 100
    color_acc = color_correct / color_total * 100
    sample_acc = sample_correct / total_samples * 100

    return avg_loss, char_acc, color_acc, sample_acc


def evaluate_fast(model, data_loader, loss_char_fn, loss_color_fn, device="cuda", max_samples=10000):
    """è¯„ä¼°æ¨¡å‹ï¼ŒéšæœºæŠ½å–max_samplesä¸ªæ ·æœ¬"""
    model.eval()

    # å…ˆæ”¶é›†æ‰€æœ‰æ•°æ®
    all_imgs = []
    all_char_gt = []
    all_color_gt = []

    print(f"  æ­£åœ¨æ”¶é›†æ•°æ®æ ·æœ¬...", end='')
    with torch.no_grad():
        for img, char_gt, color_gt in data_loader:
            all_imgs.append(img)
            all_char_gt.append(char_gt)
            all_color_gt.append(color_gt)

    # å°†æ‰€æœ‰æ‰¹æ¬¡æ•°æ®æ‹¼æ¥
    all_imgs = torch.cat(all_imgs, dim=0)
    all_char_gt = torch.cat(all_char_gt, dim=0)
    all_color_gt = torch.cat(all_color_gt, dim=0)

    total_data_size = len(all_imgs)

    # éšæœºé€‰æ‹©max_samplesä¸ªç´¢å¼•
    if total_data_size > max_samples:
        indices = torch.randperm(total_data_size)[:max_samples]
        selected_imgs = all_imgs[indices]
        selected_char_gt = all_char_gt[indices]
        selected_color_gt = all_color_gt[indices]
    else:
        selected_imgs = all_imgs
        selected_char_gt = all_char_gt
        selected_color_gt = all_color_gt
        max_samples = total_data_size

    print(f" æ€»æ•°æ®: {total_data_size}, æŠ½æ ·: {len(selected_imgs)}")

    # åˆ›å»ºå°æ‰¹é‡å¤„ç†
    eval_batch_size = data_loader.batch_size
    total_loss = 0.0
    char_correct = 0
    color_correct = 0
    char_total = 0
    color_total = 0
    sample_correct = 0

    for i in range(0, len(selected_imgs), eval_batch_size):
        end_idx = min(i + eval_batch_size, len(selected_imgs))

        batch_imgs = selected_imgs[i:end_idx].to(device)
        batch_char_gt = selected_char_gt[i:end_idx].to(device)
        batch_color_gt = selected_color_gt[i:end_idx].to(device)

        # å‰å‘ä¼ æ’­
        char_out, color_out = model(batch_imgs)

        # è®¡ç®—æŸå¤±
        loss_char = loss_char_fn(char_out, batch_char_gt)
        loss_color = loss_color_fn(color_out, batch_color_gt)
        loss = char_weight * loss_char + color_weight * loss_color
        total_loss += loss.item() * len(batch_imgs)

        # è®¡ç®—å‡†ç¡®ç‡
        batch_size = len(batch_imgs)
        char_total += batch_size * 1
        color_total += batch_size * 1

        # å­—ç¬¦å‡†ç¡®ç‡
        char_pred = char_out.view(batch_size, 1, 36).argmax(dim=2)
        char_target = batch_char_gt.view(batch_size, 1, 36).argmax(dim=2)
        char_correct += (char_pred == char_target).sum().item()

        # é¢œè‰²å‡†ç¡®ç‡
        color_pred = color_out.view(batch_size, 1, 2).argmax(dim=2)
        color_target = batch_color_gt.view(batch_size, 1, 2).argmax(dim=2)
        color_correct += (color_pred == color_target).sum().item()

        # æ ·æœ¬å‡†ç¡®ç‡
        char_correct_all = (char_pred == char_target).all(dim=1)
        color_correct_all = (color_pred == color_target).all(dim=1)
        sample_correct += (char_correct_all & color_correct_all).sum().item()

    avg_loss = total_loss / len(selected_imgs)
    char_acc = char_correct / char_total * 100
    color_acc = color_correct / color_total * 100
    sample_acc = sample_correct / len(selected_imgs) * 100

    return avg_loss, char_acc, color_acc, sample_acc

def train():
    print_header("ğŸš€ éªŒè¯ç è¯†åˆ«æ¨¡å‹è®­ç»ƒå¼€å§‹")

    # 1. æ•°æ®å‡†å¤‡é˜¶æ®µ
    print_subheader("ğŸ“ æ•°æ®å‡†å¤‡")
    transform = Compose([ToTensor()])

    print("æ­£åœ¨åŠ è½½è®­ç»ƒæ•°æ®é›†...")

    # full_dataset = CaptchaData(
    #     img_dir="./dataset/train/images",
    #     csv_path="./dataset/train/labels.csv",
    #     transform=transform,
    #     # use_augmentation=True
    # )

    full_dataset = CaptchaData(
        img_dir="./dataset/train_final/images",
        csv_path="./dataset/train_final/labels.csv",
        transform=transform,
        # use_augmentation=True
    )



    
    

    # å¦‚æœæ•°æ®é›†å¤ªå¤§ï¼Œå…ˆéšæœºæŠ½æ ·ä¸€éƒ¨åˆ†
    if len(full_dataset) > MAX_TOTAL_SAMPLES:
        print(f"  æ•°æ®é›†è¿‡å¤§ ({len(full_dataset)} æ ·æœ¬)ï¼Œè¿›è¡ŒéšæœºæŠ½æ ·...")
        indices = torch.randperm(len(full_dataset))[:MAX_TOTAL_SAMPLES]
        full_dataset = torch.utils.data.Subset(full_dataset, indices)
        print(f"  æŠ½æ ·åæ•°æ®é›†: {len(full_dataset)} æ ·æœ¬")

    # ä¿®æ”¹ï¼šåˆ’åˆ†è®­ç»ƒé›†å’ŒéªŒè¯é›†
    train_size = int((1 - val_ratio) * len(full_dataset))
    val_size = len(full_dataset) - train_size
    train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])

    print(f"âœ… æ•°æ®é›†åŠ è½½å®Œæˆ")
    print(f"  æ€»æ•°æ®é›†å¤§å°: {len(full_dataset)} å¼ å›¾ç‰‡")
    print(f"  è®­ç»ƒé›†å¤§å°: {len(train_dataset)} å¼ å›¾ç‰‡")
    print(f"  éªŒè¯é›†å¤§å°: {len(val_dataset)} å¼ å›¾ç‰‡")
    print(f"  éªŒè¯é›†æ¯”ä¾‹: {val_ratio * 100}%")



    train_loader = DataLoader(train_dataset,
                              batch_size=batch_size,
                              shuffle=True,
                              drop_last=True)

    val_loader = DataLoader(val_dataset,
                            batch_size=batch_size,
                            shuffle=False,
                            drop_last=False)
    print(f"  Batch Size: {batch_size}")
    print(f"  æ¯ä¸ªEpochçš„Batchæ•°: {len(train_loader)}")
    print(f"  æ€»è®­ç»ƒæ­¥æ•°: {max_epoch * len(train_loader)} æ­¥")

    show_freq = math.ceil(len(train_loader) / 10)


    # 2. æ¨¡å‹å‡†å¤‡é˜¶æ®µ
    print_subheader("ğŸ¤– æ¨¡å‹å‡†å¤‡")
    # model = CNN()
    # model = ResNet()
    model = ResNet18MultiTask()
    # model = EfficientCharNet()

    # è®¡ç®—æ¨¡å‹å‚æ•°é‡
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    print(f"  æ¨¡å‹: CNN")
    print(f"  æ€»å‚æ•°é‡: {total_params:,}")
    print(f"  å¯è®­ç»ƒå‚æ•°é‡: {trainable_params:,}")

    # GPUè®¾ç½®
    if torch.cuda.is_available():
        device_name = torch.cuda.get_device_name(0)
        model = model.cuda()
        print(f"  ğŸ® ä½¿ç”¨GPU: {device_name}")
    else:
        print(f"  ğŸ’» ä½¿ç”¨CPU")

    # 3. è®­ç»ƒé…ç½®
    print_subheader("âš™ï¸ è®­ç»ƒé…ç½®")
    # opt = torch.optim.Adam(model.parameters(), lr=lr)
    opt = torch.optim.AdamW(model.parameters(), 
                       lr=lr,  # é™ä½å­¦ä¹ ç‡
                       betas=(0.9, 0.999),
                       eps=1e-8,
                       weight_decay=0.01)  # æ·»åŠ æƒé‡è¡°å‡
                    #    weight_decay=0.01)  # æ·»åŠ æƒé‡è¡°å‡
    # æŸå¤±å‡½æ•°
    # loss_fn = nn.CrossEntropyLoss()
    # loss_fn = 
    loss_char_fn = nn.CrossEntropyLoss(weight=class_weights)
    loss_color_fn = nn.CrossEntropyLoss()
    # loss_fn = nn.CrossEntropyLoss(label_smoothing=0.1)
    # loss_fn = nn.MultiLabelSoftMarginLoss()

    
    scheduler = ReduceLROnPlateau(
        opt, 
        mode='min',           # ç›‘æ§æŒ‡æ ‡è¶Šå°è¶Šå¥½
        factor=2/3,          # å­¦ä¹ ç‡è¡°å‡å› å­
        patience=5,          # å®¹å¿å¤šå°‘ä¸ªepochæ²¡æœ‰æ”¹å–„
        verbose=True,        # æ‰“å°è°ƒæ•´ä¿¡æ¯
        threshold=0.0001,    # æ”¹å–„é˜ˆå€¼
        threshold_mode='rel', # ç›¸å¯¹æ”¹å–„
        cooldown=5,          # è°ƒæ•´åçš„å†·å´æœŸ
        min_lr=0.0001          # æœ€å°å­¦ä¹ ç‡
    )


    print(f"  ä¼˜åŒ–å™¨: AdamW (lr={lr})")
    print(f"  æŸå¤±å‡½æ•°: CrossEntropyLoss")
    print(f"  æœ€å¤§Epochæ•°: {max_epoch}")
    print(f"  æ¨¡å‹ä¿å­˜è·¯å¾„: {model_path}")

    # æ·»åŠ ï¼šè®°å½•æœ€ä½³éªŒè¯æŸå¤±
    best_val_loss = float('inf')
    best_epoch = 0
    best_val_sample_acc = 0

    # 4. å¼€å§‹è®­ç»ƒ
    print_header("ğŸƒ å¼€å§‹è®­ç»ƒ")

    # è®°å½•å¼€å§‹æ—¶é—´
    start_time = time.time()

    for epoch in range(max_epoch):
        print(f"\nğŸ“… Epoch {epoch + 1}/{max_epoch}")
        print(f"{'â”€' * 40}")

        # æ‰“å°å½“å‰å­¦ä¹ ç‡
        current_lr = opt.param_groups[0]['lr']
        print(f"  å½“å‰å­¦ä¹ ç‡: {current_lr:.6f}")

        epoch_start_time = time.time()
        model.train()
        total_loss = 0
        batch_count = 0

        # è¿›åº¦æ¡åˆå§‹åŒ–
        total_batches = len(train_loader)

        print("  è®­ç»ƒé˜¶æ®µ:")
        for batch_idx, (img, char_gt, color_gt) in enumerate(train_loader):
            batch_count += 1

            # æ˜¾ç¤ºè¿›åº¦
            progress = (batch_idx + 1) / total_batches * 100
            sys.stdout.write(f"\r  Batch {batch_idx + 1}/{total_batches} [{progress:.1f}%]")
            sys.stdout.flush()

            # æ•°æ®ç§»åŠ¨åˆ°GPU
            if torch.cuda.is_available():
                img = img.cuda()
                char_gt = char_gt.cuda()
                color_gt = color_gt.cuda()

            # å‰å‘ä¼ æ’­
            char_out, color_out = model(img)

            # è®¡ç®—æŸå¤±
            loss_char = loss_char_fn(char_out, char_gt)
            loss_color = loss_color_fn(color_out, color_gt)
            loss = char_weight * loss_char + color_weight * loss_color

            # åå‘ä¼ æ’­
            opt.zero_grad()
            loss.backward()
            opt.step()

            # ç´¯åŠ æŸå¤±
            total_loss += loss.item()

            # æ¯10ä¸ªbatchæ˜¾ç¤ºä¸€æ¬¡è¯¦ç»†æŸå¤±
            if (batch_idx + 1) % show_freq == 0 or (batch_idx + 1) == total_batches:
                print(f"\r  Batch {batch_idx + 1}/{total_batches} - "
                      f"Loss: {loss.item():.6f} "
                      f"(å­—ç¬¦: {loss_char.item():.6f}, "
                      f"é¢œè‰²: {loss_color.item():.6f})")

        # è®¡ç®—epochç»Ÿè®¡
        epoch_time = time.time() - epoch_start_time
        avg_loss = total_loss / len(train_loader)

      

        print(f"\n  ğŸ“Š Epoch {epoch + 1} ç»Ÿè®¡:")
        print(f"    å¹³å‡æŸå¤±: {avg_loss:.6f}")
        print(f"    æ€»æŸå¤±: {total_loss:.6f}")
        print(f"    å¤„ç†æ‰¹æ¬¡: {batch_count}")
        print(f"    è€—æ—¶: {epoch_time:.2f}ç§’")
        print(f"    æ¯æ‰¹æ¬¡å¹³å‡: {epoch_time / batch_count:.3f}ç§’")

        # ä¿®æ”¹ï¼šéªŒè¯é˜¶æ®µ
        print("  éªŒè¯é˜¶æ®µ:")
        val_loss, val_char_acc, val_color_acc, val_sample_acc = evaluate(
            model, val_loader, loss_char_fn, loss_color_fn, "cuda"
        )
        print(f"  ğŸ“Š éªŒè¯ç»Ÿè®¡:")
        print(f"    å¹³å‡æŸå¤±: {val_loss:.6f}")
        print(f"    å­—ç¬¦å‡†ç¡®ç‡: {val_char_acc:.2f}%")
        print(f"    é¢œè‰²å‡†ç¡®ç‡: {val_color_acc:.2f}%")
        print(f"    æ ·æœ¬å‡†ç¡®ç‡: {val_sample_acc:.2f}%")

        
        print("  è®­ç»ƒé›†è¯„ä¼°:")
        train_loss, train_char_acc, train_color_acc, train_sample_acc = evaluate(
            model, train_loader, loss_char_fn, loss_color_fn, "cuda"
        )
        print(f"  ğŸ“Š è®­ç»ƒç»Ÿè®¡:")
        print(f"    å¹³å‡æŸå¤±: {train_loss:.6f}")
        print(f"    å­—ç¬¦å‡†ç¡®ç‡: {train_char_acc:.2f}%")
        print(f"    é¢œè‰²å‡†ç¡®ç‡: {train_color_acc:.2f}%")
        print(f"    æ ·æœ¬å‡†ç¡®ç‡: {train_sample_acc:.2f}%")


        # ä½¿ç”¨éªŒè¯æŸå¤±æ¥è°ƒæ•´å­¦ä¹ ç‡
        if use_scheduler:
            scheduler.step(train_loss)  # å…³é”®ï¼šä¼ å…¥éªŒè¯æŸå¤±
        
            # æ£€æŸ¥å­¦ä¹ ç‡æ˜¯å¦å˜åŒ–
            new_lr = opt.param_groups[0]['lr']
            if new_lr != current_lr:
                print(f"  ğŸ”§ å­¦ä¹ ç‡å·²è°ƒæ•´: {current_lr:.6f} -> {new_lr:.6f}")
                current_lr = new_lr


        # ä¿å­˜æœ€ä½³æ¨¡å‹ï¼Œä¾æ®å‡†ç¡®ç‡
        # if val_loss < best_val_loss:
        if val_sample_acc > best_val_sample_acc:
            best_val_loss = val_loss
            best_val_sample_acc = val_sample_acc
            best_epoch = epoch + 1
            torch.save(model.state_dict(), model_path)
            print(f"  ğŸ’¾ æœ€ä½³æ¨¡å‹å·²ä¿å­˜ (Epoch {best_epoch}, Loss: {best_val_loss:.6f})")

        # ä¿å­˜æ¨¡å‹
        # torch.save(model.state_dict(), model_path)
        # print(f"  ğŸ’¾ æ¨¡å‹å·²ä¿å­˜åˆ°: {model_path}")

        # æ˜¾ç¤ºè®­ç»ƒè¿›åº¦é¢„ä¼°
        elapsed_time = time.time() - start_time
        avg_epoch_time = elapsed_time / (epoch + 1)
        remaining_epochs = max_epoch - (epoch + 1)
        remaining_time = avg_epoch_time * remaining_epochs

        hours = int(remaining_time // 3600)
        minutes = int((remaining_time % 3600) // 60)
        seconds = int(remaining_time % 60)

        print(f"  â³ å‰©ä½™æ—¶é—´: {hours:02d}:{minutes:02d}:{seconds:02d}")

    # 5. è®­ç»ƒå®Œæˆ
    print_header("âœ… è®­ç»ƒå®Œæˆ")
    total_time = time.time() - start_time

    hours = int(total_time // 3600)
    minutes = int((total_time % 3600) // 60)
    seconds = int(total_time % 60)

    print(f"  æ€»è®­ç»ƒæ—¶é—´: {hours:02d}:{minutes:02d}:{seconds:02d}")
    print(f"  æ€»Epochæ•°: {max_epoch}")
    print(f"  æ€»Batchæ•°: {max_epoch * len(train_loader)}")
    print(f"  æœ€ä½³Epoch: {best_epoch} (éªŒè¯æŸå¤±: {best_val_loss:.6f})")
    print(f"  æœ€ç»ˆæ¨¡å‹: {model_path}")

    # 6ï¼šæœ€ç»ˆè¯„ä¼°
    print_subheader("ğŸ“ˆ æœ€ç»ˆæ¨¡å‹è¯„ä¼°")

    # åŠ è½½æœ€ä½³æ¨¡å‹
    model.load_state_dict(torch.load(model_path, map_location="cuda"))

    # è¯„ä¼°è®­ç»ƒé›†
    print("  è®­ç»ƒé›†è¯„ä¼°:")
    train_loss, train_char_acc, train_color_acc, train_sample_acc = evaluate(
        model, train_loader, loss_char_fn, loss_color_fn, "cuda"
    )
    print(f"    å¹³å‡æŸå¤±: {train_loss:.6f}")
    print(f"    å­—ç¬¦å‡†ç¡®ç‡: {train_char_acc:.2f}%")
    print(f"    é¢œè‰²å‡†ç¡®ç‡: {train_color_acc:.2f}%")
    print(f"    æ ·æœ¬å‡†ç¡®ç‡: {train_sample_acc:.2f}%")

    # è¯„ä¼°éªŒè¯é›†
    print("  éªŒè¯é›†è¯„ä¼°:")
    val_loss, val_char_acc, val_color_acc, val_sample_acc = evaluate(
        model, val_loader, loss_char_fn, loss_color_fn, "cuda"
    )
    print(f"    å¹³å‡æŸå¤±: {val_loss:.6f}")
    print(f"    å­—ç¬¦å‡†ç¡®ç‡: {val_char_acc:.2f}%")
    print(f"    é¢œè‰²å‡†ç¡®ç‡: {val_color_acc:.2f}%")
    print(f"    æ ·æœ¬å‡†ç¡®ç‡: {val_sample_acc:.2f}%")

    # 7. æ¨¡å‹ä¿¡æ¯æ€»ç»“
    print_subheader("ğŸ“ˆ æ¨¡å‹æ€»ç»“")

    # è·å–æ¨¡å‹ç»“æ„ä¿¡æ¯
    print("æ¨¡å‹ç»“æ„:")
    for name, param in model.named_parameters():
        if param.requires_grad:
            # print(f"  {name:25s} | å½¢çŠ¶: {tuple(param.shape):20s} | å‚æ•°é‡: {param.numel():,}")
            print(f"  {name:25s} | å½¢çŠ¶: {str(tuple(param.shape)):20s} | å‚æ•°é‡: {param.numel():,}")

    print(f"\nğŸ‰ è®­ç»ƒå®Œæˆï¼å¯ä»¥ä½¿ç”¨æ¨¡å‹è¿›è¡ŒéªŒè¯ç è¯†åˆ«äº†ã€‚")


if __name__ == "__main__":
    train()